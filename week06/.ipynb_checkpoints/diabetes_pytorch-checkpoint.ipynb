{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "7cc4019d-4ed1-48f2-be16-93fe7cd19b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "f67d2cb4-418e-467b-b68e-cfcea9533635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 인스턴스 생성\n",
    "\n",
    "data = pd.read_csv('diabetes.csv')  # CSV 파일 경로\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "75f5d976-0845-4b77-9d59-a13f7cd8cb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.Outcome.value_counts().plot(\n",
    "    kind='pie',\n",
    "    autopct='%0.2f%%',  # 소수점 5자리 → 2자리로 변경 추천 (더 깔끔)\n",
    "    colors=['lightblue', 'lightgreen'],\n",
    "    explode=(0.05, 0.05)\n",
    ")\n",
    "plt.title(\"Distribution of Diabetes (Outcome)\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "5df00685-4569-4923-9726-0dd20e6da325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n"
     ]
    }
   ],
   "source": [
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "c77735fe-35b6-4344-8c4f-ba96c8901c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n",
    "columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', \n",
    "           'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "ddacb409-886a-433c-b45c-252d68dc44d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X (입력), y (정답) 분리\n",
    "X = data.drop(\"Outcome\", axis=1).values\n",
    "y = data[\"Outcome\"].values\n",
    "\n",
    "# torch Tensor로 변환\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "6fc0e9ee-7529-4faa-a65f-6b51a2a4ebcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "887326ba-592f-408d-90a6-2b5323423c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Outcome', axis=1).values\n",
    "y = data['Outcome'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "f0a53801-6a6c-4baa-babf-2988f08bae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "b3d1f44a-bfa9-4fd8-83b0-5798306165bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 8), (154, 8), (614,), (154,))"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "25e7d2b6-ff8d-473e-bb82-1c3de54718ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.hstack((X, y.reshape(-1, 1)))\n",
    "X_seq, y_seq = split_sequences(data_array, n_steps=5)\n",
    "\n",
    "#Convert to PyTorch tensors\n",
    "\n",
    "X_train = torch.tensor(X_seq, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_seq, dtype=torch.float32).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "ebed12af-125c-4de1-aa13-6fa9042d8945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "bef4bd93-d47a-4aa2-be20-e4614e4dd42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([764, 5, 8]),\n",
       " torch.Size([154, 8]),\n",
       " torch.Size([764, 1]),\n",
       " torch.Size([154, 1]))"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "a8e6d1a9-d815-4f2a-b74e-3b76129f0a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiabetesModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(8, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)  # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # Sigmoid는 BCEWithLogitsLoss에서 자동 적용됨\n",
    "        return x\n",
    "\n",
    "#initialize the model, loss function, and optimizer\n",
    "model = DiabetesModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "2b9a110b-df6e-443b-aec1-52f09d74bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "ae2b4346-bbb8-4e23-85ee-1e6e4ae2b692",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([32, 1])) must be the same as input size (torch.Size([32, 5, 1]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[433], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/loss.py:821\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 821\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    823\u001b[0m         target,\n\u001b[1;32m    824\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    825\u001b[0m         pos_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_weight,\n\u001b[1;32m    826\u001b[0m         reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction,\n\u001b[1;32m    827\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:3639\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3636\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[0;32m-> 3639\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3640\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3641\u001b[0m     )\n\u001b[1;32m   3643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\n\u001b[1;32m   3644\u001b[0m     \u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum\n\u001b[1;32m   3645\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([32, 1])) must be the same as input size (torch.Size([32, 5, 1]))"
     ]
    }
   ],
   "source": [
    "# 변수 초기화\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# 에폭 수 설정\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # 평균 loss 저장\n",
    "    train_losses.append(running_loss / len(train_dataloader))\n",
    "\n",
    "    # 평가 모드로 전환\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()  # ✅ 이진 분류 방식\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    test_accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_losses[-1]:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2407b9d1-ccf0-48a2-beeb-a91eba6b8f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()  # ✅ 이진 분류 방식\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_labels = np.array(all_labels).flatten()\n",
    "all_predictions = np.array(all_predictions).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions, average='binary')\n",
    "precision = precision_score(all_labels, all_predictions, average='binary')\n",
    "recall = recall_score(all_labels, all_predictions, average='binary')\n",
    "\n",
    "# Calculate specificity\n",
    "tn = conf_matrix[0, 0]\n",
    "fp = conf_matrix[0, 1]\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print results\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'Specificity: {specificity:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba447b2-6896-4e0c-b020-ebeecebebf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Test Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae870fe-d17b-44ae-b4be-15255fd73d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Outcome', axis=1).values  # Feature matrix (shape: [n_samples, 8])\n",
    "y = data['Outcome'].values               # Target vector (shape: [n_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8511774-1bb3-4842-96a8-af6507096c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec49c0-db35-4761-9c28-319c1b99f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.hstack((X, y.reshape(-1, 1)))\n",
    "data_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38070e8e-a852-4f4e-b99c-94360ee6c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=8, hidden_size=32, batch_first=True)\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]  # 마지막 시점의 출력만 사용\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88051f-1b3e-4bf0-85c4-0b8624b8f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38633b-13e3-4f56-bfbb-9f414e185647",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesCNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiabetesCNN1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 5, 64)  # 시퀀스 길이 5 기준\n",
    "        self.fc2 = nn.Linear(64, 1)       # 이진 분류이므로 출력 1개\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f651ff-ac71-4a5e-87c4-720609b89b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.permute(0, 2, 1)\n",
    "X_test = X_test.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "cc10e2a0-4e20-4941-a5ae-168cc2272d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiabetesCNN1D()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "f09a5dbe-0c54-4f30-b641-9b2961a802ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch shape: torch.Size([32, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train batch shape:\", next(iter(train_dataloader))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "1bfc5526-5772-49b6-a2ac-d3968fa26362",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 8, 3], expected input[32, 5, 8] to have 8 channels, but got 5 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[447], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[357], line 10\u001b[0m, in \u001b[0;36mDiabetesCNN1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 10\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))\n\u001b[1;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[1;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    372\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 8, 3], expected input[32, 5, 8] to have 8 channels, but got 5 channels instead"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_dataloader:\n",
    "    inputs = inputs.permute(0, 2, 1)  \n",
    "    labels = labels.float().unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_losses.append(running_loss / len(train_dataloader))\n",
    "\n",
    "    # 평가\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs = inputs.permute(0, 2, 1) \n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    test_accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_losses[-1]:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# 평가 지표 출력\n",
    "all_labels = np.array(all_labels).flatten()\n",
    "all_predictions = np.array(all_predictions).flatten()\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions, average='binary')\n",
    "precision = precision_score(all_labels, all_predictions, average='binary')\n",
    "recall = recall_score(all_labels, all_predictions, average='binary')\n",
    "\n",
    "tn = conf_matrix[0, 0]\n",
    "fp = conf_matrix[0, 1]\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")\n",
    "\n",
    "# 그래프\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Test Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7777d433-7fb3-48a8-aae1-1ddc40328dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
