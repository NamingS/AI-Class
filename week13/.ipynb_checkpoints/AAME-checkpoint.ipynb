{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20bb64e8-91f3-4d4a-9cea-7d6585345d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdadbf01-2321-409a-b189-4f0e4148664d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-03-17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.213167</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-03-18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.171437</td>\n",
       "      <td>10200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-03-19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.213167</td>\n",
       "      <td>33500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-03-20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.171437</td>\n",
       "      <td>8700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-03-21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.129709</td>\n",
       "      <td>12700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10093</th>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>2.29</td>\n",
       "      <td>2.29</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.28</td>\n",
       "      <td>2.280000</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10094</th>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10095</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.130000</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10096</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.110000</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10097</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10098 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Open  High   Low  Close  Adj Close  Volume\n",
       "0     1980-03-17  0.00  4.05  3.85   3.85   3.213167   15000\n",
       "1     1980-03-18  0.00  4.00  3.80   3.80   3.171437   10200\n",
       "2     1980-03-19  0.00  4.05  3.85   3.85   3.213167   33500\n",
       "3     1980-03-20  0.00  4.00  3.80   3.80   3.171437    8700\n",
       "4     1980-03-21  0.00  3.95  3.75   3.75   3.129709   12700\n",
       "...          ...   ...   ...   ...    ...        ...     ...\n",
       "10093 2020-03-26  2.29  2.29  2.08   2.28   2.280000    1600\n",
       "10094 2020-03-27  2.25  2.25  2.21   2.25   2.250000     500\n",
       "10095 2020-03-30  2.25  2.25  2.13   2.13   2.130000     400\n",
       "10096 2020-03-31  2.11  2.11  2.11   2.11   2.110000     300\n",
       "10097 2020-04-01  2.11  2.15  2.11   2.15   2.150000     600\n",
       "\n",
       "[10098 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"AAME.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.sort_values('Date', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fcdd0bc-86b6-452c-9519-819f563f4425",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['Open', 'High', 'Low', 'Close']].copy()\n",
    "features.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e8cfd7c-b060-4fdb-b0c7-e15e1a9faecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64db82ba-1b43-4b18-9f60-23c7e9e2a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length, -1])\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54207ece-a189-4bc0-8e53-cbe240d80cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 30\n",
    "X, y = create_sequences(scaled_features, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d9cbb38-2e8a-4888-817a-91be33badece",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "221b4b7c-f7ce-4844-b4c1-a3c7c0982ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5aaf417-3ddf-4704-b393-ffab235da8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa937d27-80d3-4bd9-bc78-24906f2d833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, num_epochs=50):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            output = model(x_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d4698e4-7216-401c-a2b2-4dc49efdb146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, scaler, close_index):\n",
    "    model.eval()\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            output = model(x_batch)\n",
    "            predictions.append(output.numpy())\n",
    "            actuals.append(y_batch.numpy())\n",
    "\n",
    "    y_pred = np.concatenate(predictions)\n",
    "    y_true = np.concatenate(actuals)\n",
    "\n",
    "    # 역정규화\n",
    "    min_val = scaler.data_min_[close_index]\n",
    "    max_val = scaler.data_max_[close_index]\n",
    "    y_pred_unscaled = y_pred * (max_val - min_val) + min_val\n",
    "    y_true_unscaled = y_true * (max_val - min_val) + min_val\n",
    "\n",
    "    mse = mean_squared_error(y_true_unscaled, y_pred_unscaled)\n",
    "    mae = mean_absolute_error(y_true_unscaled, y_pred_unscaled)\n",
    "\n",
    "    return y_pred_unscaled, y_true_unscaled, mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7596d76d-ac0e-4fc6-95da-b7f7071b4b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Training RNN...\n",
      "Epoch 1/50, Loss: 0.001590\n",
      "Epoch 2/50, Loss: 0.000143\n",
      "Epoch 3/50, Loss: 0.000142\n",
      "Epoch 4/50, Loss: 0.000120\n",
      "Epoch 5/50, Loss: 0.000118\n",
      "Epoch 6/50, Loss: 0.000115\n",
      "Epoch 7/50, Loss: 0.000103\n",
      "Epoch 8/50, Loss: 0.000106\n",
      "Epoch 9/50, Loss: 0.000120\n",
      "Epoch 10/50, Loss: 0.000101\n",
      "Epoch 11/50, Loss: 0.000112\n",
      "Epoch 12/50, Loss: 0.000097\n",
      "Epoch 13/50, Loss: 0.000104\n",
      "Epoch 14/50, Loss: 0.000095\n",
      "Epoch 15/50, Loss: 0.000090\n",
      "Epoch 16/50, Loss: 0.000090\n",
      "Epoch 17/50, Loss: 0.000100\n",
      "Epoch 18/50, Loss: 0.000100\n",
      "Epoch 19/50, Loss: 0.000106\n",
      "Epoch 20/50, Loss: 0.000094\n",
      "Epoch 21/50, Loss: 0.000093\n",
      "Epoch 22/50, Loss: 0.000093\n",
      "Epoch 23/50, Loss: 0.000094\n",
      "Epoch 24/50, Loss: 0.000097\n",
      "Epoch 25/50, Loss: 0.000094\n",
      "Epoch 26/50, Loss: 0.000092\n",
      "Epoch 27/50, Loss: 0.000100\n",
      "Epoch 28/50, Loss: 0.000096\n",
      "Epoch 29/50, Loss: 0.000096\n",
      "Epoch 30/50, Loss: 0.000096\n",
      "Epoch 31/50, Loss: 0.000105\n",
      "Epoch 32/50, Loss: 0.000090\n",
      "Epoch 33/50, Loss: 0.000097\n",
      "Epoch 34/50, Loss: 0.000099\n",
      "Epoch 35/50, Loss: 0.000102\n",
      "Epoch 36/50, Loss: 0.000097\n",
      "Epoch 37/50, Loss: 0.000093\n",
      "Epoch 38/50, Loss: 0.000098\n",
      "Epoch 39/50, Loss: 0.000099\n",
      "Epoch 40/50, Loss: 0.000094\n",
      "Epoch 41/50, Loss: 0.000093\n",
      "Epoch 42/50, Loss: 0.000094\n",
      "Epoch 43/50, Loss: 0.000092\n",
      "Epoch 44/50, Loss: 0.000090\n",
      "Epoch 45/50, Loss: 0.000093\n",
      "Epoch 46/50, Loss: 0.000099\n",
      "Epoch 47/50, Loss: 0.000094\n",
      "Epoch 48/50, Loss: 0.000088\n",
      "Epoch 49/50, Loss: 0.000088\n",
      "Epoch 50/50, Loss: 0.000090\n",
      "\n",
      "🔁 Training LSTM...\n",
      "Epoch 1/50, Loss: 0.010450\n",
      "Epoch 2/50, Loss: 0.000290\n",
      "Epoch 3/50, Loss: 0.000216\n",
      "Epoch 4/50, Loss: 0.000186\n",
      "Epoch 5/50, Loss: 0.000175\n",
      "Epoch 6/50, Loss: 0.000175\n",
      "Epoch 7/50, Loss: 0.000163\n",
      "Epoch 8/50, Loss: 0.000145\n",
      "Epoch 9/50, Loss: 0.000140\n",
      "Epoch 10/50, Loss: 0.000141\n",
      "Epoch 11/50, Loss: 0.000137\n",
      "Epoch 12/50, Loss: 0.000142\n",
      "Epoch 13/50, Loss: 0.000127\n",
      "Epoch 14/50, Loss: 0.000132\n",
      "Epoch 15/50, Loss: 0.000134\n",
      "Epoch 16/50, Loss: 0.000141\n",
      "Epoch 17/50, Loss: 0.000117\n",
      "Epoch 18/50, Loss: 0.000132\n",
      "Epoch 19/50, Loss: 0.000105\n",
      "Epoch 20/50, Loss: 0.000116\n",
      "Epoch 21/50, Loss: 0.000118\n",
      "Epoch 22/50, Loss: 0.000114\n",
      "Epoch 23/50, Loss: 0.000101\n",
      "Epoch 24/50, Loss: 0.000095\n",
      "Epoch 25/50, Loss: 0.000120\n",
      "Epoch 26/50, Loss: 0.000107\n",
      "Epoch 27/50, Loss: 0.000093\n",
      "Epoch 28/50, Loss: 0.000093\n",
      "Epoch 29/50, Loss: 0.000097\n",
      "Epoch 30/50, Loss: 0.000090\n",
      "Epoch 31/50, Loss: 0.000100\n",
      "Epoch 32/50, Loss: 0.000090\n",
      "Epoch 33/50, Loss: 0.000087\n",
      "Epoch 34/50, Loss: 0.000096\n",
      "Epoch 35/50, Loss: 0.000090\n",
      "Epoch 36/50, Loss: 0.000081\n",
      "Epoch 37/50, Loss: 0.000089\n",
      "Epoch 38/50, Loss: 0.000080\n",
      "Epoch 39/50, Loss: 0.000081\n",
      "Epoch 40/50, Loss: 0.000091\n",
      "Epoch 41/50, Loss: 0.000086\n",
      "Epoch 42/50, Loss: 0.000086\n",
      "Epoch 43/50, Loss: 0.000083\n",
      "Epoch 44/50, Loss: 0.000085\n",
      "Epoch 45/50, Loss: 0.000091\n",
      "Epoch 46/50, Loss: 0.000088\n",
      "Epoch 47/50, Loss: 0.000086\n",
      "Epoch 48/50, Loss: 0.000084\n",
      "Epoch 49/50, Loss: 0.000081\n",
      "Epoch 50/50, Loss: 0.000087\n",
      "\n",
      "📊 [RNN] Test MSE: 0.0092, MAE: 0.0643\n",
      "📊 [LSTM] Test MSE: 0.0090, MAE: 0.0647\n"
     ]
    }
   ],
   "source": [
    "input_size = 4\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "close_index = features.columns.get_loc(\"Close\")\n",
    "\n",
    "print(\"\\n🔁 Training RNN...\")\n",
    "rnn = RNNModel(input_size, hidden_size, num_layers)\n",
    "train_model(rnn, train_loader)\n",
    "\n",
    "print(\"\\n🔁 Training LSTM...\")\n",
    "lstm = LSTMModel(input_size, hidden_size, num_layers)\n",
    "train_model(lstm, train_loader)\n",
    "\n",
    "rnn_preds, rnn_true, rnn_mse, rnn_mae = evaluate_model(rnn, test_loader, scaler, close_index)\n",
    "lstm_preds, lstm_true, lstm_mse, lstm_mae = evaluate_model(lstm, test_loader, scaler, close_index)\n",
    "\n",
    "print(f\"\\n📊 [RNN] Test MSE: {rnn_mse:.4f}, MAE: {rnn_mae:.4f}\")\n",
    "print(f\"📊 [LSTM] Test MSE: {lstm_mse:.4f}, MAE: {lstm_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383b5553-cfcb-42b1-bbe2-2566b2f6fe3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
